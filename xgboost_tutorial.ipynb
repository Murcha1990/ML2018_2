{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='blue'>XGBoost</font> eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/dmlc/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Установка:</h2>\n",
    "\n",
    "\n",
    "git clone --recursive https://github.com/dmlc/xgboost\n",
    "\n",
    "cd xgboost; make -j4\n",
    "\n",
    "cd python-package; sudo python setup.py install\n",
    "\n",
    "export PYTHONPATH=/path/to/xgboost/python-package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем датасет Boston Housing и обучим XGBoost на нем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "\n",
    "kf = KFold(y.shape[0], n_folds=2, shuffle=True, random_state=rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost предлагает 2 способа использования алгоритмов:\n",
    "* sklearn-совместимые классы XGBClassifier, XGBRegressor\n",
    "\n",
    "* \"оригинальная\" python-библиотека"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on fold 0: 4.71669323912\n",
      "RMSE on fold 1: 3.14875583423\n"
     ]
    }
   ],
   "source": [
    "for fold_index, (train_index, test_index) in enumerate(kf):\n",
    "    xgb_model = xgb.XGBRegressor().fit(X[train_index], y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print \"RMSE on fold {}: {}\".format(fold_index, np.sqrt(mean_squared_error(actuals, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on fold 0: [0]\teval-rmse:5.111199\n",
      "RMSE on fold 1: [0]\teval-rmse:3.336737\n"
     ]
    }
   ],
   "source": [
    "def get_params():\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"booster\"] = \"gbtree\"\n",
    "    params[\"eval_metric\"] = \"rmse\"\n",
    "    params[\"num_boost_round\"] = 100\n",
    "    params[\"max_depth\"] = 3\n",
    "    params[\"tree_method\"] = \"approx\"\n",
    "    params[\"sketch_eps\"] = 1\n",
    "    \n",
    "    return params\n",
    "    \n",
    "for fold_index, (train_index, test_index) in enumerate(kf):\n",
    "\n",
    "    params = get_params()\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
    "    xgtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
    "\n",
    "    bst = xgb.train(params, xgtrain)\n",
    "\n",
    "    print \"RMSE on fold {}: {}\".format(fold_index, bst.eval(xgtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Градиентный бустинг на решающих деревьях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Хотим построить композицию алгоритмов:\n",
    "<font size=5>\n",
    "\n",
    "$$ \\hat{y_i} = \\phi(x_i) = \\sum_{k=1}^{K} f_k(x_i) $$\n",
    "\n",
    "$$ Obj(f) = \\sum_{i} l(y_i, \\hat{y_i} ) + \\sum_k \\Omega(f_k)$$\n",
    "\n",
    "$$ \\Omega(f_k) = \\gamma T + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_j^2 + \\alpha\\sum_{j=1}^{T}w_j$$\n",
    "\n",
    "\n",
    "<font size=3>\n",
    "\n",
    "$ x_i, y_i, \\hat{y_i} $ - i-ый объект, правильный ответ и предсказание модели для для него\n",
    "\n",
    "$ \\Omega $ - регуляризация\n",
    "\n",
    "T - количество листьев в дереве\n",
    "\n",
    "$ w_j $ - веса, проставленные в листьях дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преимущества:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* потенциально очень высокое качество во многих задачах\n",
    "\n",
    "* находит нелинейные связи\n",
    "\n",
    "* способен обработать датасеты с большим числом объектов и признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Недостатки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* очень много параметров\n",
    "\n",
    "* модели не интерпретируемы\n",
    "\n",
    "* по умолчанию не очень быстрый"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Особенности XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Написан на C++, есть обертки на Python, R, Java, Scala\n",
    "\n",
    "С помощью XGBoost выиграна половина конкурсов на Kaggle\n",
    "\n",
    "Существует коммерческая версия TreeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Для уменьшения переобучения целевая функция поддерживает L0, L1, L2 регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Параллелизм (по признакам)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://zhanpengfang.github.io/fig_418/feature_speedup.png\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "Также есть возможность запускаться на Hadoop, Spark, Flink и DataFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомные функции потерь / метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В XGBoost встроено множество различных функций потерь:\n",
    "\n",
    "* reg:linear\n",
    "\n",
    "* reg:logistic\n",
    "\n",
    "* binary:logistic\n",
    "\n",
    "* binary:logitraw\n",
    "\n",
    "* multi:softmax\n",
    "\n",
    "* rank:pairwise\n",
    "\n",
    "* ...\n",
    "\n",
    "А также соответствующих eval_metric, которые замеряют качество и позволяют сделать early stop.\n",
    "\n",
    "Но также имеется возможность реализовать свой objective и eval_metric.\n",
    "\n",
    "Все, что для этого нужно - уметь считать градиент и гессиан."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_reg_linear(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    grad = (preds - labels)\n",
    "    hess = np.ones(labels.shape[0])\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.111199\n",
      "[0]\teval-rmse:3.336737\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "    params = get_params()\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X[train_index], label=y[train_index])\n",
    "    xgtest = xgb.DMatrix(X[test_index], label=y[test_index])\n",
    "\n",
    "    bst = xgb.train(params, xgtrain, obj=my_reg_linear)\n",
    "    \n",
    "    predictions = bst.predict(xgtest)\n",
    "    actuals = y[test_index]\n",
    "\n",
    "    print bst.eval(xgtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximated tree splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данных слишком много, то можно использовать не все значения признаков, а разделить их на бакеты.\n",
    "\n",
    "А именно, от каждого признака берутся не все значения, а только некоторое подмножество. Разбиение производится по элементам этого подмножества. \n",
    "\n",
    "Для разбиения выбираются взвешенные перцентили.\n",
    "\n",
    "В оригинальной статье указывается 2 алгоритма:\n",
    "*   глобальный - один раз выбрать разбиение значений фактора перед началом построения дерева и зафиксировать\n",
    "\n",
    "    экономим на выборе разбиений, но обычно приходится выбирать больше точек разбиения\n",
    "    \n",
    "    \n",
    "*   локальный - выбирать разбиение после каждого сплита\n",
    "  \n",
    "    работает лучше на глубоких деревьях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params[\"tree_method\"] = \"approx\"\n",
    "params[\"sketch_eps\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пропуски в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost умеет обрабатывать разреженные матрицы\n",
    "\n",
    "Но категориальные признаки нужно приводить к числовому виду\n",
    "\n",
    "Нужно указать, какое число является \"пропуском\"\n",
    "\n",
    "При сплите, алгоритм смотрит в какую сторону лучше отвести объекты с пропуском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain_missed = xgb.DMatrix(X[test_index], label=y[test_index], missing=-999.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитывает сколько раз каждый признак использовался для использовался в вершине дерева при разбиении\n",
    "\n",
    "Это не качество фактора, а его важность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 9,\n",
       " 'f10': 5,\n",
       " 'f12': 15,\n",
       " 'f3': 1,\n",
       " 'f4': 8,\n",
       " 'f5': 12,\n",
       " 'f6': 3,\n",
       " 'f7': 8,\n",
       " 'f9': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xed17710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd328400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAGHCAYAAAAdnkAlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQDAFCIDAJhCZAAAU4gMAGCKD8rog01G5lycAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x558d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прунинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно GBM перестает разделять вершины дерева, когда gain становится отрицательным - жадный подход.\n",
    "Могло оказаться так, что после неудачного сплита с отрицательным gain'ом получится сделать сильно положительный сплит.\n",
    "\n",
    "XGBoost доводит деревья до max_depth, после чего начинает удалять сплиты, которые несут отрицательный вклад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дообучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start running example to start from a initial prediction\n",
      "[0]\teval-error:0.042831\ttrain-error:0.046522\n",
      "this is result of running from initial prediction\n",
      "[0]\teval-error:0.021726\ttrain-error:0.022263\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix('../xgboost/demo//data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../xgboost/demo/data/agaricus.txt.test')\n",
    "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "###\n",
    "# advanced: start from a initial base prediction\n",
    "#\n",
    "print ('start running example to start from a initial prediction')\n",
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "# train xgboost for 1 round\n",
    "bst = xgb.train( param, dtrain, 1, watchlist )\n",
    "\n",
    "# Note: we need the margin value instead of transformed prediction in set_base_margin\n",
    "# do predict with output_margin=True, will always give you margin values before logistic transformation\n",
    "ptrain = bst.predict(dtrain, output_margin=True)\n",
    "ptest  = bst.predict(dtest, output_margin=True)\n",
    "\n",
    "dtrain.set_base_margin(ptrain)\n",
    "dtest.set_base_margin(ptest)\n",
    "\n",
    "print ('this is result of running from initial prediction')\n",
    "bst = xgb.train( param, dtrain, 1, watchlist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенная кросс валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022267</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0          0.046530        0.004219          0.046530         0.001407\n",
       "1          0.022267        0.002827          0.022267         0.000942\n",
       "2          0.007064        0.001408          0.007064         0.000469\n",
       "3          0.015203        0.001811          0.015203         0.000603\n",
       "4          0.007064        0.001408          0.007064         0.000469\n",
       "5          0.001997        0.001097          0.001945         0.001370\n",
       "6          0.001228        0.000615          0.001228         0.000205\n",
       "7          0.001228        0.000615          0.001228         0.000205\n",
       "8          0.001228        0.000615          0.001228         0.000205\n",
       "9          0.001075        0.000798          0.000870         0.000529\n",
       "10         0.000922        0.000922          0.000512         0.000512\n",
       "11         0.000922        0.000922          0.000409         0.000434\n",
       "12         0.000461        0.000798          0.000153         0.000266\n",
       "13         0.000461        0.000798          0.000153         0.000266\n",
       "14         0.000461        0.000798          0.000153         0.000266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.cv(param, dtrain, nfold = 4, num_boost_round=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 вида бустеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gbtree - обычные решающие деревья\n",
    "\n",
    "* gblinear - линейные модели\n",
    "\n",
    "* dart - решающие деревья, алгоритм может \"выбрасывать\" некоторые из деревьев, уменьшая переобучение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Веса для объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем учитывать каждый объект со своим весом, этот вес будет учитываться и при выборе бакетов при приближенном построении деревьев, при сплите, при подсчете Objective.\n",
    "\n",
    "Допустим, мы хотим классифицировать короткие сообщения.  Некоторые из них повторяются. В этом случае выгодно \"слить\" вместе все дубликаты и посчитать их один раз, но с большим весом. При неизменном качестве это уменьшит время обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated dataset. Train size: 739, error: [0]\teval-rmse:6.220294\n",
      "Weighted dataset. Train size: 300, error: [0]\teval-rmse:6.220294\n"
     ]
    }
   ],
   "source": [
    "repeats = np.random.randint(low=1, high=5, size=X.shape[0])\n",
    "train_examples = 300\n",
    "\n",
    "\n",
    "X_train = X[:train_examples]\n",
    "X_test = X[train_examples:]\n",
    "y_train = y[:train_examples]\n",
    "y_test = y[train_examples:]\n",
    "\n",
    "\n",
    "X_train_repeated = np.repeat(X_train, repeats[:train_examples], axis=0)\n",
    "X_test_repeated = np.repeat(X_test, repeats[train_examples:], axis=0)\n",
    "y_train_repeated = np.repeat(y_train, repeats[:train_examples], axis=0)\n",
    "\n",
    "\n",
    "xgtrain_repeated = xgb.DMatrix(X_train_repeated, label=y_train_repeated)\n",
    "xgtrain_weighted = xgb.DMatrix(X_train, label=y_train, weight=repeats[:train_examples])\n",
    "\n",
    "xgtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "bst = xgb.train(params, xgtrain_repeated)\n",
    "print \"Repeated dataset. Train size: {}, error: {}\".format(xgtrain_repeated.num_row(), bst.eval(xgtest))\n",
    "\n",
    "bst = xgb.train(params, xgtrain_weighted)\n",
    "print \"Weighted dataset. Train size: {}, error: {}\".format(xgtrain_weighted.num_row(), bst.eval(xgtest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Другие параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> learning_rates </i> - можно настроить убывающую скорость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "<i> max_depth </i> - максимальная глубина дерева. Слишком большая глубина ведет к переобучению\n",
    "\n",
    "<i> subsample, colsample_bytree, colsample_bylevel </i> - сэмплирование по объектам и признакам\n",
    "\n",
    "\n",
    "<i> min_child_weight </i> - минимальная сумма весов в листе\n",
    "\n",
    "<i> scale_pos_weight </i> - вес целого класса, используется если один класс заметно чаще встречается, чем другой\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные параметры для DART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "<i> sample_type </i> - стратегия выбора деревьев для выкидывания\n",
    "\n",
    "<i> rate_drop </i> - какую долю выкидываем\n",
    "\n",
    "<i> skip_drop </i> - шанс пропустить дроп на этой итерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настраиваем XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "* Выбираем относительно большую learning_rate ($ \\eta \\in [0.05, 0.3]$), подбираем оптимальное число деревьев для выбранного $ \\eta $\n",
    "\n",
    "* Настраиваем параметры деревьев, начиная с самых значимых (max_depth, min_child_weight, gamma, subsample, colsample_bytree)\n",
    "\n",
    "* Настраиваем регуляризации ($ \\lambda, \\alpha $)\n",
    "\n",
    "* Уменьшаем learning_rate, пропорционально увеличиваем число деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
